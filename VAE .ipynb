{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "# from torchvision import datasets, transforms\n",
    "import dataset\n",
    "import mainmodel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 256)\n",
      "(500, 256)\n",
      "----------------------\n",
      "(100, 256)\n",
      "(100, 256)\n",
      "----------------------\n",
      "(100, 256)\n",
      "100\n",
      "----------------------\n",
      "(500, 256)\n",
      "(100, 256)\n",
      "1148 0\n",
      "rate 0.9\n",
      "data.shape[0]: 500\n",
      "rate 450\n",
      "TrainData (1000, 256, 1, 1, 256)\n",
      "TestData (50, 256)\n",
      "ÄnomalyDta (100, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Dataset = dataset.dataset(\"Obrid_AE\", \"data\")\n",
    "Dataset.concat_data(\"sample_data\",500)\n",
    "Dataset = dataset.dataset(\"Obrid_AE\", \"test\")\n",
    "print(\"----------------------\")\n",
    "Dataset.concat_data(\"sample_test\",100)\n",
    "print(\"----------------------\")\n",
    "data = Dataset.read_savedata(\"sample_test\")\n",
    "print(data.shape[0])\n",
    "print(\"----------------------\")\n",
    "data, test_data , anomaly_data= Dataset.read_traindata(\"sample_data\", \"sample_test\", 1000, 256, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://standardfrancis.files.wordpress.com/2015/04/screenshot-from-2015-04-16-133436.png?w=1008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, shape, epsilon=np.float32(1e-5)):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.tensor(np.ones(shape, dtype='float32')))\n",
    "        self.beta = nn.Parameter(torch.tensor(np.zeros(shape, dtype='float32')))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = torch.mean(x, (0, 2, 3), keepdim=True)\n",
    "        std = torch.std(x, (0, 2, 3), keepdim=True)\n",
    "        x_normalized = (x - mean) / (std**2 + self.epsilon)**0.5\n",
    "        return self.gamma * x_normalized + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.log(0)によるnanを防ぐ\n",
    "def torch_log(x):\n",
    "    return torch.log(torch.clamp(x, min=1e-10))\n",
    "\n",
    "\n",
    "class AE(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.enc1 = nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 7, stride = 5)\n",
    "        self.enc2 = nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5, stride = 3)\n",
    "        self.flat = nn.Flatten(0, -1)\n",
    "        self.enc3 = nn.Linear(16, z_dim)\n",
    "\n",
    "        self.encmean = nn.Linear(16, z_dim)\n",
    "        self.encvar = nn.Linear(16, z_dim)\n",
    "\n",
    "        # self.dec1 = nn.Linear(z_dim, 200)\n",
    "        self.dec1 = nn.Linear(z_dim,  16)\n",
    "        self.unflat = nn.Unflatten(0, (1, 1 ,16))\n",
    "        self.dec2 = nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5, stride = 3, output_padding=1)\n",
    "        self.dec3 = nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 7, stride = 5, padding = 1, output_padding=1)\n",
    "\n",
    "\n",
    "    def _encoder(self, x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        x = self.flat(x)\n",
    "        mean = self.encmean(x)\n",
    "        var = F.softplus(self.encvar(x))\n",
    "        return mean, var\n",
    "\n",
    "    def _sample_z(self, mean, var):\n",
    "        epsilon = torch.randn(mean.shape).to(device)\n",
    "        return mean + torch.sqrt(var) * epsilon\n",
    "\n",
    "    def _decoder(self, z):\n",
    "        x = F.relu(self.dec1(z))\n",
    "        x = self.unflat(x)\n",
    "        x = F.relu(self.dec2(x))\n",
    "        x = torch.sigmoid(self.dec3(x))\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, var = self._encoder(x)\n",
    "        z = self._sample_z(mean, var)\n",
    "        x = self._decoder(z)\n",
    "        return x, z\n",
    "\n",
    "    def loss(self, x):\n",
    "        mean, var = self._encoder(x)\n",
    "        # print(mean, var)\n",
    "        # KL lossの計算\n",
    "        KL = -0.5 * torch.mean(torch.sum(1 + torch_log(var) - mean**2 - var, dim=0))\n",
    "        \n",
    "        z = self._sample_z(mean, var)\n",
    "        y = self._decoder(z)\n",
    "\n",
    "        # reconstruction lossの計算\n",
    "        reconstruction = torch.mean(torch.sum(x * torch_log(y) + (1 - x) * torch_log(1 - y), dim=0))\n",
    "\n",
    "        return KL, -reconstruction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0072,  0.0283,  0.1305], grad_fn=<AddBackward0>) tensor([0.6292, 0.6073, 0.7090], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0062,  0.0273,  0.1295], grad_fn=<AddBackward0>) tensor([0.6297, 0.6078, 0.7095], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0052,  0.0263,  0.1285], grad_fn=<AddBackward0>) tensor([0.6302, 0.6083, 0.7100], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0042,  0.0253,  0.1275], grad_fn=<AddBackward0>) tensor([0.6306, 0.6087, 0.7105], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0033,  0.0243,  0.1265], grad_fn=<AddBackward0>) tensor([0.6311, 0.6092, 0.7110], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0023,  0.0233,  0.1255], grad_fn=<AddBackward0>) tensor([0.6316, 0.6096, 0.7115], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0015,  0.0224,  0.1245], grad_fn=<AddBackward0>) tensor([0.6320, 0.6101, 0.7121], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0214,  0.1235], grad_fn=<AddBackward0>) tensor([0.6325, 0.6105, 0.7126], grad_fn=<SoftplusBackward0>)\n",
      "tensor([1.1946e-04, 2.0404e-02, 1.2249e-01], grad_fn=<AddBackward0>) tensor([0.6330, 0.6110, 0.7131], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0008, 0.0194, 0.1215], grad_fn=<AddBackward0>) tensor([0.6334, 0.6115, 0.7136], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0013, 0.0185, 0.1205], grad_fn=<AddBackward0>) tensor([0.6339, 0.6119, 0.7141], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0018, 0.0175, 0.1195], grad_fn=<AddBackward0>) tensor([0.6344, 0.6124, 0.7146], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0021, 0.0166, 0.1185], grad_fn=<AddBackward0>) tensor([0.6348, 0.6128, 0.7151], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0023, 0.0157, 0.1175], grad_fn=<AddBackward0>) tensor([0.6353, 0.6133, 0.7156], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0025, 0.0148, 0.1165], grad_fn=<AddBackward0>) tensor([0.6358, 0.6137, 0.7161], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0025, 0.0139, 0.1156], grad_fn=<AddBackward0>) tensor([0.6363, 0.6142, 0.7166], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0024, 0.0130, 0.1146], grad_fn=<AddBackward0>) tensor([0.6367, 0.6147, 0.7171], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0022, 0.0121, 0.1136], grad_fn=<AddBackward0>) tensor([0.6372, 0.6151, 0.7177], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0020, 0.0113, 0.1126], grad_fn=<AddBackward0>) tensor([0.6377, 0.6156, 0.7182], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0018, 0.0104, 0.1117], grad_fn=<AddBackward0>) tensor([0.6381, 0.6160, 0.7187], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0015, 0.0096, 0.1107], grad_fn=<AddBackward0>) tensor([0.6386, 0.6165, 0.7192], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0012, 0.0088, 0.1097], grad_fn=<AddBackward0>) tensor([0.6391, 0.6169, 0.7197], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0008, 0.0081, 0.1087], grad_fn=<AddBackward0>) tensor([0.6395, 0.6174, 0.7202], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0005, 0.0073, 0.1078], grad_fn=<AddBackward0>) tensor([0.6400, 0.6179, 0.7207], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0002, 0.0066, 0.1068], grad_fn=<AddBackward0>) tensor([0.6405, 0.6183, 0.7212], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0001,  0.0059,  0.1059], grad_fn=<AddBackward0>) tensor([0.6409, 0.6188, 0.7217], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0004,  0.0053,  0.1049], grad_fn=<AddBackward0>) tensor([0.6414, 0.6192, 0.7222], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0046,  0.1040], grad_fn=<AddBackward0>) tensor([0.6419, 0.6197, 0.7227], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0008,  0.0040,  0.1030], grad_fn=<AddBackward0>) tensor([0.6424, 0.6202, 0.7233], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0009,  0.0034,  0.1021], grad_fn=<AddBackward0>) tensor([0.6428, 0.6206, 0.7238], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0010,  0.0029,  0.1011], grad_fn=<AddBackward0>) tensor([0.6433, 0.6211, 0.7243], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0010,  0.0024,  0.1002], grad_fn=<AddBackward0>) tensor([0.6438, 0.6215, 0.7248], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0010,  0.0019,  0.0993], grad_fn=<AddBackward0>) tensor([0.6442, 0.6220, 0.7253], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0009,  0.0014,  0.0983], grad_fn=<AddBackward0>) tensor([0.6447, 0.6224, 0.7258], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0008,  0.0010,  0.0974], grad_fn=<AddBackward0>) tensor([0.6452, 0.6229, 0.7263], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0007,  0.0006,  0.0965], grad_fn=<AddBackward0>) tensor([0.6456, 0.6234, 0.7268], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0003,  0.0956], grad_fn=<AddBackward0>) tensor([0.6461, 0.6238, 0.7273], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.3353e-04, -5.0873e-05,  9.4645e-02], grad_fn=<AddBackward0>) tensor([0.6466, 0.6243, 0.7278], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0003, -0.0003,  0.0937], grad_fn=<AddBackward0>) tensor([0.6470, 0.6247, 0.7283], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0001, -0.0006,  0.0928], grad_fn=<AddBackward0>) tensor([0.6475, 0.6252, 0.7288], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2.0666e-05, -8.6070e-04,  9.1930e-02], grad_fn=<AddBackward0>) tensor([0.6480, 0.6256, 0.7293], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0002, -0.0011,  0.0910], grad_fn=<AddBackward0>) tensor([0.6485, 0.6261, 0.7298], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0003, -0.0013,  0.0901], grad_fn=<AddBackward0>) tensor([0.6489, 0.6266, 0.7304], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0004, -0.0014,  0.0893], grad_fn=<AddBackward0>) tensor([0.6494, 0.6270, 0.7309], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0004, -0.0016,  0.0884], grad_fn=<AddBackward0>) tensor([0.6499, 0.6275, 0.7314], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0005, -0.0017,  0.0875], grad_fn=<AddBackward0>) tensor([0.6503, 0.6279, 0.7319], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0005, -0.0018,  0.0866], grad_fn=<AddBackward0>) tensor([0.6508, 0.6284, 0.7324], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0005, -0.0018,  0.0857], grad_fn=<AddBackward0>) tensor([0.6513, 0.6288, 0.7329], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0004, -0.0019,  0.0849], grad_fn=<AddBackward0>) tensor([0.6517, 0.6293, 0.7334], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0004, -0.0019,  0.0840], grad_fn=<AddBackward0>) tensor([0.6522, 0.6298, 0.7339], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0003, -0.0019,  0.0832], grad_fn=<AddBackward0>) tensor([0.6527, 0.6302, 0.7344], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0003, -0.0019,  0.0823], grad_fn=<AddBackward0>) tensor([0.6531, 0.6307, 0.7349], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0002, -0.0019,  0.0815], grad_fn=<AddBackward0>) tensor([0.6536, 0.6311, 0.7354], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 9.3276e-05, -1.8513e-03,  8.0631e-02], grad_fn=<AddBackward0>) tensor([0.6541, 0.6316, 0.7359], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.4654e-05, -1.8064e-03,  7.9795e-02], grad_fn=<AddBackward0>) tensor([0.6545, 0.6320, 0.7364], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.8222e-05, -1.7510e-03,  7.8963e-02], grad_fn=<AddBackward0>) tensor([0.6550, 0.6325, 0.7369], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0001, -0.0017,  0.0781], grad_fn=<AddBackward0>) tensor([0.6555, 0.6330, 0.7374], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0016,  0.0773], grad_fn=<AddBackward0>) tensor([0.6559, 0.6334, 0.7379], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0015,  0.0765], grad_fn=<AddBackward0>) tensor([0.6564, 0.6339, 0.7384], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0014,  0.0757], grad_fn=<AddBackward0>) tensor([0.6569, 0.6343, 0.7389], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0014,  0.0749], grad_fn=<AddBackward0>) tensor([0.6573, 0.6348, 0.7394], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0013,  0.0741], grad_fn=<AddBackward0>) tensor([0.6578, 0.6352, 0.7399], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0012,  0.0733], grad_fn=<AddBackward0>) tensor([0.6583, 0.6357, 0.7404], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0011,  0.0725], grad_fn=<AddBackward0>) tensor([0.6587, 0.6362, 0.7409], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0010,  0.0717], grad_fn=<AddBackward0>) tensor([0.6592, 0.6366, 0.7414], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0001, -0.0009,  0.0709], grad_fn=<AddBackward0>) tensor([0.6597, 0.6371, 0.7419], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.2971e-05, -7.8148e-04,  7.0140e-02], grad_fn=<AddBackward0>) tensor([0.6601, 0.6375, 0.7424], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.6909e-05, -6.8788e-04,  6.9368e-02], grad_fn=<AddBackward0>) tensor([0.6606, 0.6380, 0.7429], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.6386e-05, -5.9674e-04,  6.8601e-02], grad_fn=<AddBackward0>) tensor([0.6611, 0.6384, 0.7434], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 5.2928e-05, -5.0838e-04,  6.7838e-02], grad_fn=<AddBackward0>) tensor([0.6615, 0.6389, 0.7439], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 8.3330e-05, -4.2343e-04,  6.7081e-02], grad_fn=<AddBackward0>) tensor([0.6620, 0.6393, 0.7444], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0001, -0.0003,  0.0663], grad_fn=<AddBackward0>) tensor([0.6625, 0.6398, 0.7449], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0001, -0.0003,  0.0656], grad_fn=<AddBackward0>) tensor([0.6629, 0.6403, 0.7454], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0001, -0.0002,  0.0648], grad_fn=<AddBackward0>) tensor([0.6634, 0.6407, 0.7459], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0001, -0.0001,  0.0641], grad_fn=<AddBackward0>) tensor([0.6639, 0.6412, 0.7464], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.3063e-04, -6.9922e-05,  6.3373e-02], grad_fn=<AddBackward0>) tensor([0.6643, 0.6416, 0.7469], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.1805e-04, -1.5078e-05,  6.2646e-02], grad_fn=<AddBackward0>) tensor([0.6648, 0.6421, 0.7474], grad_fn=<SoftplusBackward0>)\n",
      "tensor([9.9532e-05, 3.4762e-05, 6.1925e-02], grad_fn=<AddBackward0>) tensor([0.6653, 0.6425, 0.7479], grad_fn=<SoftplusBackward0>)\n",
      "tensor([7.6839e-05, 7.9638e-05, 6.1209e-02], grad_fn=<AddBackward0>) tensor([0.6657, 0.6430, 0.7484], grad_fn=<SoftplusBackward0>)\n",
      "tensor([5.6488e-05, 1.1871e-04, 6.0498e-02], grad_fn=<AddBackward0>) tensor([0.6662, 0.6434, 0.7489], grad_fn=<SoftplusBackward0>)\n",
      "tensor([3.4576e-05, 1.5293e-04, 5.9792e-02], grad_fn=<AddBackward0>) tensor([0.6666, 0.6439, 0.7493], grad_fn=<SoftplusBackward0>)\n",
      "tensor([5.4394e-06, 1.8397e-04, 5.9091e-02], grad_fn=<AddBackward0>) tensor([0.6671, 0.6443, 0.7498], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.1290e-05,  2.1024e-04,  5.8395e-02], grad_fn=<AddBackward0>) tensor([0.6676, 0.6448, 0.7503], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.2541e-05,  2.3119e-04,  5.7705e-02], grad_fn=<AddBackward0>) tensor([0.6680, 0.6453, 0.7508], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.5708e-05,  2.4629e-04,  5.7020e-02], grad_fn=<AddBackward0>) tensor([0.6685, 0.6457, 0.7513], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.3472e-05,  2.5773e-04,  5.6340e-02], grad_fn=<AddBackward0>) tensor([0.6690, 0.6462, 0.7518], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.5862e-05,  2.6571e-04,  5.5665e-02], grad_fn=<AddBackward0>) tensor([0.6694, 0.6466, 0.7523], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.3792e-05,  2.7019e-04,  5.4995e-02], grad_fn=<AddBackward0>) tensor([0.6699, 0.6471, 0.7528], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.1548e-05,  2.7090e-04,  5.4330e-02], grad_fn=<AddBackward0>) tensor([0.6704, 0.6475, 0.7533], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.2175e-05,  2.6837e-04,  5.3671e-02], grad_fn=<AddBackward0>) tensor([0.6708, 0.6480, 0.7538], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.8406e-05,  2.6469e-04,  5.3016e-02], grad_fn=<AddBackward0>) tensor([0.6713, 0.6484, 0.7543], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.3415e-05,  2.5855e-04,  5.2367e-02], grad_fn=<AddBackward0>) tensor([0.6717, 0.6489, 0.7548], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.2234e-05,  2.4980e-04,  5.1723e-02], grad_fn=<AddBackward0>) tensor([0.6722, 0.6493, 0.7552], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.2616e-07,  2.3957e-04,  5.1084e-02], grad_fn=<AddBackward0>) tensor([0.6727, 0.6498, 0.7557], grad_fn=<SoftplusBackward0>)\n",
      "tensor([1.5502e-05, 2.2623e-04, 5.0450e-02], grad_fn=<AddBackward0>) tensor([0.6731, 0.6502, 0.7562], grad_fn=<SoftplusBackward0>)\n",
      "tensor([2.8963e-05, 2.1171e-04, 4.9822e-02], grad_fn=<AddBackward0>) tensor([0.6736, 0.6507, 0.7567], grad_fn=<SoftplusBackward0>)\n",
      "tensor([4.2533e-05, 1.9563e-04, 4.9198e-02], grad_fn=<AddBackward0>) tensor([0.6740, 0.6511, 0.7572], grad_fn=<SoftplusBackward0>)\n",
      "tensor([5.1918e-05, 1.7894e-04, 4.8580e-02], grad_fn=<AddBackward0>) tensor([0.6745, 0.6516, 0.7577], grad_fn=<SoftplusBackward0>)\n",
      "tensor([5.6859e-05, 1.6187e-04, 4.7967e-02], grad_fn=<AddBackward0>) tensor([0.6750, 0.6521, 0.7582], grad_fn=<SoftplusBackward0>)\n",
      "tensor([4.9216e-05, 1.4588e-04, 4.7358e-02], grad_fn=<AddBackward0>) tensor([0.6754, 0.6525, 0.7587], grad_fn=<SoftplusBackward0>)\n",
      "tensor([3.3903e-05, 1.3024e-04, 4.6755e-02], grad_fn=<AddBackward0>) tensor([0.6759, 0.6530, 0.7592], grad_fn=<SoftplusBackward0>)\n",
      "tensor([1.8656e-05, 1.1508e-04, 4.6157e-02], grad_fn=<AddBackward0>) tensor([0.6764, 0.6534, 0.7596], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.9047e-06,  1.0133e-04,  4.5564e-02], grad_fn=<AddBackward0>) tensor([0.6768, 0.6539, 0.7601], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.8268e-05,  8.8604e-05,  4.4977e-02], grad_fn=<AddBackward0>) tensor([0.6773, 0.6543, 0.7606], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.6244e-05,  7.3216e-05,  4.4394e-02], grad_fn=<AddBackward0>) tensor([0.6777, 0.6548, 0.7611], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.7541e-05,  5.8901e-05,  4.3817e-02], grad_fn=<AddBackward0>) tensor([0.6782, 0.6552, 0.7616], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.2946e-05,  4.5279e-05,  4.3244e-02], grad_fn=<AddBackward0>) tensor([0.6787, 0.6557, 0.7621], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.2610e-05,  3.2436e-05,  4.2677e-02], grad_fn=<AddBackward0>) tensor([0.6791, 0.6561, 0.7626], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.2019e-05,  1.7780e-05,  4.2115e-02], grad_fn=<AddBackward0>) tensor([0.6796, 0.6566, 0.7630], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.8038e-05,  5.4486e-06,  4.1558e-02], grad_fn=<AddBackward0>) tensor([0.6800, 0.6570, 0.7635], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.1734e-05, -7.9360e-06,  4.1006e-02], grad_fn=<AddBackward0>) tensor([0.6805, 0.6575, 0.7640], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.0662e-05, -1.9557e-05,  4.0459e-02], grad_fn=<AddBackward0>) tensor([0.6809, 0.6579, 0.7645], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.5713e-05, -2.9282e-05,  3.9917e-02], grad_fn=<AddBackward0>) tensor([0.6814, 0.6584, 0.7650], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.7001e-05, -3.8060e-05,  3.9380e-02], grad_fn=<AddBackward0>) tensor([0.6819, 0.6588, 0.7654], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.7125e-05, -4.5543e-05,  3.8848e-02], grad_fn=<AddBackward0>) tensor([0.6823, 0.6593, 0.7659], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.9205e-06, -5.1764e-05,  3.8321e-02], grad_fn=<AddBackward0>) tensor([0.6828, 0.6597, 0.7664], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.1856e-05, -5.3475e-05,  3.7799e-02], grad_fn=<AddBackward0>) tensor([0.6832, 0.6602, 0.7669], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.5428e-05, -5.4376e-05,  3.7282e-02], grad_fn=<AddBackward0>) tensor([0.6837, 0.6606, 0.7674], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.7494e-05, -5.4531e-05,  3.6770e-02], grad_fn=<AddBackward0>) tensor([0.6842, 0.6611, 0.7679], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.8036e-05, -5.4007e-05,  3.6262e-02], grad_fn=<AddBackward0>) tensor([0.6846, 0.6615, 0.7683], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.7155e-05, -5.2872e-05,  3.5760e-02], grad_fn=<AddBackward0>) tensor([0.6851, 0.6620, 0.7688], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.5047e-05, -5.1197e-05,  3.5262e-02], grad_fn=<AddBackward0>) tensor([0.6855, 0.6624, 0.7693], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.5059e-05, -4.9224e-05,  3.4770e-02], grad_fn=<AddBackward0>) tensor([0.6860, 0.6629, 0.7698], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.2035e-05, -4.2871e-05,  3.4282e-02], grad_fn=<AddBackward0>) tensor([0.6864, 0.6633, 0.7702], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.0541e-05, -3.5057e-05,  3.3799e-02], grad_fn=<AddBackward0>) tensor([0.6869, 0.6638, 0.7707], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.8465e-05, -2.8583e-05,  3.3321e-02], grad_fn=<AddBackward0>) tensor([0.6874, 0.6642, 0.7712], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.7073e-05, -2.2989e-05,  3.2848e-02], grad_fn=<AddBackward0>) tensor([0.6878, 0.6647, 0.7717], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.9227e-05, -1.7064e-05,  3.2379e-02], grad_fn=<AddBackward0>) tensor([0.6883, 0.6651, 0.7722], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.2474e-05, -1.3334e-05,  3.1916e-02], grad_fn=<AddBackward0>) tensor([0.6887, 0.6656, 0.7726], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.8203e-05, -1.3300e-05,  3.1458e-02], grad_fn=<AddBackward0>) tensor([0.6892, 0.6660, 0.7731], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-8.7608e-06, -1.6007e-05,  3.1005e-02], grad_fn=<AddBackward0>) tensor([0.6896, 0.6664, 0.7736], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.1105e-05, -1.7440e-05,  3.0557e-02], grad_fn=<AddBackward0>) tensor([0.6901, 0.6669, 0.7741], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 3.5262e-05, -1.9883e-05,  3.0113e-02], grad_fn=<AddBackward0>) tensor([0.6905, 0.6673, 0.7745], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 7.5894e-05, -2.6530e-05,  2.9674e-02], grad_fn=<AddBackward0>) tensor([0.6910, 0.6678, 0.7750], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.1112e-04, -3.7431e-05,  2.9241e-02], grad_fn=<AddBackward0>) tensor([0.6915, 0.6682, 0.7755], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.3395e-04, -4.6793e-05,  2.8811e-02], grad_fn=<AddBackward0>) tensor([0.6919, 0.6687, 0.7760], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 8.8118e-05, -5.5874e-05,  2.8386e-02], grad_fn=<AddBackward0>) tensor([0.6924, 0.6691, 0.7764], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2.3447e-05, -5.9545e-05,  2.7966e-02], grad_fn=<AddBackward0>) tensor([0.6928, 0.6696, 0.7769], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.1977e-05, -5.6290e-05,  2.7550e-02], grad_fn=<AddBackward0>) tensor([0.6933, 0.6700, 0.7774], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.1954e-04, -5.0516e-05,  2.7139e-02], grad_fn=<AddBackward0>) tensor([0.6937, 0.6705, 0.7778], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.4285e-04, -4.7324e-05,  2.6733e-02], grad_fn=<AddBackward0>) tensor([0.6942, 0.6709, 0.7783], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.5470e-04, -4.8284e-05,  2.6331e-02], grad_fn=<AddBackward0>) tensor([0.6946, 0.6714, 0.7788], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.6473e-04, -5.2579e-05,  2.5934e-02], grad_fn=<AddBackward0>) tensor([0.6951, 0.6718, 0.7793], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.7097e-04, -5.2879e-05,  2.5542e-02], grad_fn=<AddBackward0>) tensor([0.6955, 0.6723, 0.7797], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.2622e-04, -5.3944e-05,  2.5154e-02], grad_fn=<AddBackward0>) tensor([0.6960, 0.6727, 0.7802], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.0819e-05, -5.9782e-05,  2.4771e-02], grad_fn=<AddBackward0>) tensor([0.6964, 0.6731, 0.7807], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.5791e-05, -6.3003e-05,  2.4392e-02], grad_fn=<AddBackward0>) tensor([0.6969, 0.6736, 0.7811], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.8426e-05, -6.5741e-05,  2.4019e-02], grad_fn=<AddBackward0>) tensor([0.6973, 0.6740, 0.7816], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.1070e-05, -6.9635e-05,  2.3649e-02], grad_fn=<AddBackward0>) tensor([0.6978, 0.6745, 0.7821], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 2.8638e-05, -7.6944e-05,  2.3284e-02], grad_fn=<AddBackward0>) tensor([0.6982, 0.6749, 0.7825], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 3.6695e-05, -8.2691e-05,  2.2922e-02], grad_fn=<AddBackward0>) tensor([0.6987, 0.6754, 0.7830], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 6.7519e-05, -9.0882e-05,  2.2565e-02], grad_fn=<AddBackward0>) tensor([0.6992, 0.6758, 0.7835], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.1493e-04, -9.4838e-05,  2.2212e-02], grad_fn=<AddBackward0>) tensor([0.6996, 0.6763, 0.7839], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 1.5242e-04, -9.7808e-05,  2.1864e-02], grad_fn=<AddBackward0>) tensor([0.7001, 0.6767, 0.7844], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0002, -0.0001,  0.0215], grad_fn=<AddBackward0>) tensor([0.7005, 0.6772, 0.7849], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 9.5678e-05, -9.7953e-05,  2.1178e-02], grad_fn=<AddBackward0>) tensor([0.7010, 0.6776, 0.7853], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.7844e-05, -9.1872e-05,  2.0842e-02], grad_fn=<AddBackward0>) tensor([0.7014, 0.6780, 0.7858], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.6754e-04, -8.0608e-05,  2.0510e-02], grad_fn=<AddBackward0>) tensor([0.7019, 0.6785, 0.7863], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.9491e-04, -7.7448e-05,  2.0182e-02], grad_fn=<AddBackward0>) tensor([0.7023, 0.6789, 0.7867], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.0062e-04, -6.7338e-05,  1.9858e-02], grad_fn=<AddBackward0>) tensor([0.7028, 0.6794, 0.7872], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.5499e-04, -6.5606e-05,  1.9539e-02], grad_fn=<AddBackward0>) tensor([0.7032, 0.6798, 0.7877], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.6736e-04, -6.7334e-05,  1.9226e-02], grad_fn=<AddBackward0>) tensor([0.7037, 0.6803, 0.7881], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.4349e-04, -6.4551e-05,  1.8917e-02], grad_fn=<AddBackward0>) tensor([0.7041, 0.6807, 0.7886], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.4693e-04, -7.6816e-05,  1.8612e-02], grad_fn=<AddBackward0>) tensor([0.7046, 0.6811, 0.7891], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.7266e-04, -7.9222e-05,  1.8311e-02], grad_fn=<AddBackward0>) tensor([0.7050, 0.6816, 0.7895], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.3105e-04, -7.4613e-05,  1.8014e-02], grad_fn=<AddBackward0>) tensor([0.7055, 0.6820, 0.7900], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.7333e-04, -6.7133e-05,  1.7721e-02], grad_fn=<AddBackward0>) tensor([0.7059, 0.6825, 0.7904], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.5690e-04, -4.7620e-05,  1.7431e-02], grad_fn=<AddBackward0>) tensor([0.7063, 0.6829, 0.7909], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.1058e-04, -2.2286e-05,  1.7146e-02], grad_fn=<AddBackward0>) tensor([0.7068, 0.6834, 0.7914], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.0540e-04,  6.3422e-06,  1.6864e-02], grad_fn=<AddBackward0>) tensor([0.7072, 0.6838, 0.7918], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.7008e-04,  2.2256e-05,  1.6587e-02], grad_fn=<AddBackward0>) tensor([0.7077, 0.6842, 0.7923], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.1224e-04,  2.6512e-05,  1.6313e-02], grad_fn=<AddBackward0>) tensor([0.7081, 0.6847, 0.7927], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.0902e-04,  3.3292e-05,  1.6043e-02], grad_fn=<AddBackward0>) tensor([0.7086, 0.6851, 0.7932], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.6347e-05,  2.9707e-05,  1.5777e-02], grad_fn=<AddBackward0>) tensor([0.7090, 0.6856, 0.7937], grad_fn=<SoftplusBackward0>)\n",
      "tensor([2.2819e-04, 1.6582e-05, 1.5515e-02], grad_fn=<AddBackward0>) tensor([0.7095, 0.6860, 0.7941], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 4.6696e-04, -1.1320e-05,  1.5257e-02], grad_fn=<AddBackward0>) tensor([0.7099, 0.6864, 0.7946], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 6.4499e-04, -3.5110e-05,  1.5003e-02], grad_fn=<AddBackward0>) tensor([0.7104, 0.6869, 0.7950], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 8.1141e-04, -7.0031e-05,  1.4753e-02], grad_fn=<AddBackward0>) tensor([0.7108, 0.6873, 0.7955], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0009, -0.0001,  0.0145], grad_fn=<AddBackward0>) tensor([0.7113, 0.6878, 0.7959], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0008, -0.0002,  0.0143], grad_fn=<AddBackward0>) tensor([0.7117, 0.6882, 0.7964], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0007, -0.0002,  0.0140], grad_fn=<AddBackward0>) tensor([0.7122, 0.6886, 0.7968], grad_fn=<SoftplusBackward0>)\n",
      "tensor([ 0.0002, -0.0002,  0.0138], grad_fn=<AddBackward0>) tensor([0.7126, 0.6891, 0.7973], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0003, -0.0002,  0.0136], grad_fn=<AddBackward0>) tensor([0.7131, 0.6895, 0.7978], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0008, -0.0002,  0.0133], grad_fn=<AddBackward0>) tensor([0.7135, 0.6900, 0.7982], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0013, -0.0001,  0.0131], grad_fn=<AddBackward0>) tensor([0.7139, 0.6904, 0.7987], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0017, -0.0001,  0.0129], grad_fn=<AddBackward0>) tensor([0.7144, 0.6908, 0.7991], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0020, -0.0001,  0.0127], grad_fn=<AddBackward0>) tensor([0.7148, 0.6913, 0.7996], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.2465e-03, -9.5701e-05,  1.2457e-02], grad_fn=<AddBackward0>) tensor([0.7153, 0.6917, 0.8000], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-2.2345e-03, -8.2947e-05,  1.2247e-02], grad_fn=<AddBackward0>) tensor([0.7157, 0.6922, 0.8005], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.9143e-03, -8.8419e-05,  1.2039e-02], grad_fn=<AddBackward0>) tensor([0.7162, 0.6926, 0.8009], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.4205e-03, -9.7347e-05,  1.1835e-02], grad_fn=<AddBackward0>) tensor([0.7166, 0.6930, 0.8014], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0010, -0.0001,  0.0116], grad_fn=<AddBackward0>) tensor([0.7171, 0.6935, 0.8018], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005, -0.0001,  0.0114], grad_fn=<AddBackward0>) tensor([0.7175, 0.6939, 0.8023], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0001,  0.0112], grad_fn=<AddBackward0>) tensor([0.7179, 0.6943, 0.8027], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.2086e-05, -1.4389e-04,  1.1063e-02], grad_fn=<AddBackward0>) tensor([0.7184, 0.6948, 0.8032], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-8.6563e-05, -1.4394e-04,  1.0882e-02], grad_fn=<AddBackward0>) tensor([0.7188, 0.6952, 0.8036], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-7.1446e-05, -1.7110e-04,  1.0705e-02], grad_fn=<AddBackward0>) tensor([0.7193, 0.6957, 0.8041], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-4.7618e-05, -1.9569e-04,  1.0534e-02], grad_fn=<AddBackward0>) tensor([0.7197, 0.6961, 0.8045], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002, -0.0002,  0.0104], grad_fn=<AddBackward0>) tensor([0.7202, 0.6965, 0.8050], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0003, -0.0001,  0.0102], grad_fn=<AddBackward0>) tensor([0.7206, 0.6970, 0.8054], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006, -0.0001,  0.0100], grad_fn=<AddBackward0>) tensor([0.7210, 0.6974, 0.8059], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.6135e-04, -9.0915e-05,  9.8827e-03], grad_fn=<AddBackward0>) tensor([0.7215, 0.6978, 0.8063], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.3307e-04, -4.2938e-05,  9.7306e-03], grad_fn=<AddBackward0>) tensor([0.7219, 0.6983, 0.8068], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.7881e-04, -1.3610e-05,  9.5804e-03], grad_fn=<AddBackward0>) tensor([0.7224, 0.6987, 0.8072], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-5.5529e-04,  2.9449e-05,  9.4333e-03], grad_fn=<AddBackward0>) tensor([0.7228, 0.6992, 0.8076], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005,  0.0001,  0.0093], grad_fn=<AddBackward0>) tensor([0.7232, 0.6996, 0.8081], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005,  0.0002,  0.0091], grad_fn=<AddBackward0>) tensor([0.7237, 0.7000, 0.8085], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005,  0.0004,  0.0090], grad_fn=<AddBackward0>) tensor([0.7241, 0.7005, 0.8090], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002,  0.0005,  0.0089], grad_fn=<AddBackward0>) tensor([0.7246, 0.7009, 0.8094], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.7807e-05,  5.4930e-04,  8.7292e-03], grad_fn=<AddBackward0>) tensor([0.7250, 0.7013, 0.8099], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002,  0.0006,  0.0086], grad_fn=<AddBackward0>) tensor([0.7254, 0.7018, 0.8103], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0007,  0.0085], grad_fn=<AddBackward0>) tensor([0.7259, 0.7022, 0.8107], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0007,  0.0008,  0.0083], grad_fn=<AddBackward0>) tensor([0.7263, 0.7026, 0.8112], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0008,  0.0082], grad_fn=<AddBackward0>) tensor([0.7268, 0.7031, 0.8116], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005,  0.0008,  0.0081], grad_fn=<AddBackward0>) tensor([0.7272, 0.7035, 0.8121], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0003,  0.0008,  0.0080], grad_fn=<AddBackward0>) tensor([0.7276, 0.7039, 0.8125], grad_fn=<SoftplusBackward0>)\n",
      "tensor([4.6015e-05, 7.8133e-04, 7.8790e-03], grad_fn=<AddBackward0>) tensor([0.7281, 0.7044, 0.8130], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0003, 0.0008, 0.0078], grad_fn=<AddBackward0>) tensor([0.7285, 0.7048, 0.8134], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0006, 0.0007, 0.0077], grad_fn=<AddBackward0>) tensor([0.7289, 0.7053, 0.8138], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0005, 0.0007, 0.0076], grad_fn=<AddBackward0>) tensor([0.7294, 0.7057, 0.8143], grad_fn=<SoftplusBackward0>)\n",
      "tensor([0.0003, 0.0007, 0.0075], grad_fn=<AddBackward0>) tensor([0.7298, 0.7061, 0.8147], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002,  0.0007,  0.0074], grad_fn=<AddBackward0>) tensor([0.7303, 0.7066, 0.8151], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0007,  0.0073], grad_fn=<AddBackward0>) tensor([0.7307, 0.7070, 0.8156], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0007,  0.0007,  0.0072], grad_fn=<AddBackward0>) tensor([0.7311, 0.7074, 0.8160], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0006,  0.0007,  0.0071], grad_fn=<AddBackward0>) tensor([0.7316, 0.7079, 0.8164], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005,  0.0006,  0.0070], grad_fn=<AddBackward0>) tensor([0.7320, 0.7083, 0.8169], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0003,  0.0005,  0.0069], grad_fn=<AddBackward0>) tensor([0.7324, 0.7087, 0.8173], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.6384e-05,  4.0052e-04,  6.8740e-03], grad_fn=<AddBackward0>) tensor([0.7329, 0.7091, 0.8178], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-8.2232e-05,  3.3893e-04,  6.7999e-03], grad_fn=<AddBackward0>) tensor([0.7333, 0.7096, 0.8182], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-3.3743e-05,  3.0439e-04,  6.7323e-03], grad_fn=<AddBackward0>) tensor([0.7337, 0.7100, 0.8186], grad_fn=<SoftplusBackward0>)\n",
      "tensor([2.6352e-05, 3.2238e-04, 6.6606e-03], grad_fn=<AddBackward0>) tensor([0.7342, 0.7104, 0.8191], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0001,  0.0003,  0.0066], grad_fn=<AddBackward0>) tensor([0.7346, 0.7109, 0.8195], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-6.4003e-05,  2.9802e-04,  6.5307e-03], grad_fn=<AddBackward0>) tensor([0.7350, 0.7113, 0.8199], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0002,  0.0003,  0.0065], grad_fn=<AddBackward0>) tensor([0.7355, 0.7117, 0.8204], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0005,  0.0001,  0.0064], grad_fn=<AddBackward0>) tensor([0.7359, 0.7122, 0.8208], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.1850e-03,  2.5444e-05,  6.3546e-03], grad_fn=<AddBackward0>) tensor([0.7363, 0.7126, 0.8212], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-1.6085e-03, -4.7406e-05,  6.3006e-03], grad_fn=<AddBackward0>) tensor([0.7368, 0.7130, 0.8217], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0018, -0.0002,  0.0062], grad_fn=<AddBackward0>) tensor([0.7372, 0.7135, 0.8221], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0018, -0.0004,  0.0062], grad_fn=<AddBackward0>) tensor([0.7376, 0.7139, 0.8225], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0018, -0.0006,  0.0062], grad_fn=<AddBackward0>) tensor([0.7381, 0.7143, 0.8230], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0016, -0.0008,  0.0061], grad_fn=<AddBackward0>) tensor([0.7385, 0.7147, 0.8234], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0014, -0.0009,  0.0061], grad_fn=<AddBackward0>) tensor([0.7389, 0.7152, 0.8238], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0013, -0.0009,  0.0060], grad_fn=<AddBackward0>) tensor([0.7394, 0.7156, 0.8242], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0016, -0.0009,  0.0060], grad_fn=<AddBackward0>) tensor([0.7398, 0.7160, 0.8247], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0021, -0.0008,  0.0059], grad_fn=<AddBackward0>) tensor([0.7402, 0.7165, 0.8251], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0026, -0.0007,  0.0059], grad_fn=<AddBackward0>) tensor([0.7407, 0.7169, 0.8255], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0025, -0.0006,  0.0058], grad_fn=<AddBackward0>) tensor([0.7411, 0.7173, 0.8259], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0023, -0.0004,  0.0058], grad_fn=<AddBackward0>) tensor([0.7415, 0.7178, 0.8264], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0021, -0.0002,  0.0057], grad_fn=<AddBackward0>) tensor([0.7420, 0.7182, 0.8268], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0019,  0.0001,  0.0057], grad_fn=<AddBackward0>) tensor([0.7424, 0.7186, 0.8272], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0014,  0.0003,  0.0056], grad_fn=<AddBackward0>) tensor([0.7428, 0.7190, 0.8276], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0014,  0.0006,  0.0056], grad_fn=<AddBackward0>) tensor([0.7433, 0.7195, 0.8281], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0017,  0.0009,  0.0055], grad_fn=<AddBackward0>) tensor([0.7437, 0.7199, 0.8285], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0018,  0.0011,  0.0054], grad_fn=<AddBackward0>) tensor([0.7441, 0.7203, 0.8289], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0021,  0.0012,  0.0054], grad_fn=<AddBackward0>) tensor([0.7445, 0.7207, 0.8293], grad_fn=<SoftplusBackward0>)\n",
      "tensor([-0.0021,  0.0013,  0.0053], grad_fn=<AddBackward0>) tensor([0.7450, 0.7212, 0.8298], grad_fn=<SoftplusBackward0>)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gl/kcbdb7pj0yz8846ytcdrjm140000gn/T/ipykernel_3147/2689105978.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#     losses_val.append(loss.cpu().detach().numpy())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n\u001b[0m\u001b[1;32m     30\u001b[0m         (epoch+1, np.average(losses), np.average(KL_losses), np.average(reconstruction_losses)))\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "z_dim = 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AE(z_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "input_data = torch.from_numpy(data.astype(np.float32)).clone()\n",
    "input_test_data = torch.from_numpy(test_data.astype(np.float32)).clone()\n",
    "for epoch in input_data:\n",
    "    losses = []\n",
    "    KL_losses = []\n",
    "    reconstruction_losses = []\n",
    "    model.train()\n",
    "    for x in epoch:\n",
    "        model.zero_grad()\n",
    "        KL_loss, reconstruction_loss = model.loss(x)  # lossの各項の計算\n",
    "        loss = KL_loss + reconstruction_loss  # 和を取ってlossとする\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().numpy())\n",
    "        KL_losses.append(KL_loss.detach().numpy())\n",
    "        reconstruction_losses.append(reconstruction_loss.detach().numpy())\n",
    "\n",
    "    losses_val = []\n",
    "    model.eval()\n",
    "    # for x in input_test_data:\n",
    "    #     KL_loss, reconstruction_loss = model.loss(x)\n",
    "    #     loss = KL_loss + reconstruction_loss\n",
    "    #     losses_val.append(loss.cpu().detach().numpy())\n",
    "\n",
    "    # print('EPOCH:%d, Train Lower Bound:%lf, (%lf, %lf), Valid Lower Bound:%lf' %\n",
    "    #     (epoch+1, np.average(losses), np.average(KL_losses), np.average(reconstruction_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"newmodel\"\n",
    "# ModelEdit = mainmodel.Modeledit(\"syuron\")\n",
    "# ModelEdit.save_model(model, model_name) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5f3f9be2ca8d53a2d9e5a69008919cdcaa5ea3bae845fdf455c7915f0fd9345"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('lab2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
